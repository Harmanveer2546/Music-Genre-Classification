{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c6ee7e",
   "metadata": {},
   "source": [
    "# Music Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7700e2f",
   "metadata": {},
   "source": [
    "### Classifying the genre of a music using deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee5c54",
   "metadata": {},
   "source": [
    "Music Genre classification is one of the branches of Music Information Retrieval (MIR). A robust recommendation system begins with the categorization of music genres. Sound processing is a huge reaseach area through which we can find solutions to various medical or mental issues through music theraphy solutions. There are various music applications such as Spotify, Google Play, Apple Music, etc., but for implementation, one of the most important steps is to classify the genre of a music which requires audio processing, it is one of the most complex tasks that involves time signal processing, time series, spectrograms, spectral coefficients, and audio feature extraction to feed a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d1638",
   "metadata": {},
   "source": [
    "## Import libraries and Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6414a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef76139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For warnings-\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file-\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\features_3_sec.csv\")\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\features_30_sec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256020cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ce405",
   "metadata": {},
   "source": [
    "#### Termology-\n",
    "\n",
    "1. filename: The name or identifier of the audio file.\n",
    "2. length: The duration or length of the audio file in seconds.\n",
    "3. chroma_stft_mean: The mean value of the chroma feature computed using the short-time Fourier transform (STFT). It represents the distribution of pitches or musical notes in the audio.\n",
    "4. chroma_stft_var: The variance of the chroma feature.\n",
    "5. rms_mean: The root mean square (RMS) value of the audio signal, which represents the overall amplitude or loudness.\n",
    "6. rms_var: The variance of the RMS value.\n",
    "7. spectral_centroid_mean: The mean frequency value weighted by the magnitude spectrum. It represents the center of mass of the spectrum and provides information about the brightness of the sound.\n",
    "8. spectral_centroid_var: The variance of the spectral centroid.\n",
    "9. spectral_bandwidth_mean: The mean bandwidth of the magnitude spectrum. It represents the range of frequencies in the signal.\n",
    "10. spectral_bandwidth_var: The variance of the spectral bandwidth.\n",
    "11. rolloff_mean: The mean frequency value below which a specified percentage of the total spectral energy lies.\n",
    "12. rolloff_var: The variance of the spectral rolloff.\n",
    "13. zero_crossing_rate_mean: The rate of sign-changes of the audio signal. It represents the frequency content or noisiness of the signal.\n",
    "14. zero_crossing_rate_var: The variance of the zero-crossing rate.\n",
    "15. harmony_mean: The mean value of the harmonic component of the audio signal.\n",
    "16. harmony_var: The variance of the harmonic component.\n",
    "17. perceptr_mean: The mean value of the perceptual spread of the audio signal.\n",
    "18. perceptr_var: The variance of the perceptual spread.\n",
    "19. tempo: The estimated tempo or beats per minute (BPM) of the audio.\n",
    "20. mfcc1_mean to mfcc20_var: Mel-frequency cepstral coefficients (MFCCs) are commonly used features in audio signal processing. These terms represent the mean and variance values of the 20 MFCCs.\n",
    "21. label: The class label or category assigned to the audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be3730",
   "metadata": {},
   "source": [
    "## EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65749a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Top 5 Reccords-\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking last 5 records-\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b423843",
   "metadata": {},
   "outputs": [],
   "source": [
    "list[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7118d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting familiar with the structure of the dataset-\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207178b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45006ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To know more about the dataset with transpose – here T is for the transpose\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27487b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skewness-\n",
    "\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf13243",
   "metadata": {},
   "source": [
    "#### Skewness is a measurement of the distortion of symmetrical distribution or asymmetry in a data set. Skewness is demonstrated on a bell curve when data points are not distributed symmetrically to the left and right sides of the median on a bell curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff94de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa5c9c",
   "metadata": {},
   "source": [
    "#### Kurtosis is a measure of the tailedness of a distribution. Tailedness is how often outliers occur. Excess kurtosis is the tailedness of a distribution relative to a normal distribution. Distributions with medium kurtosis (medium tails) are mesokurtic. Distributions with low kurtosis (thin tails) are platykurtic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Duplicates- \n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let’s check that if our dataset have null values or not\n",
    "\n",
    "df.isnull().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b36a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing value heatmap-\n",
    "\n",
    "sns.heatmap(df.isnull(),cbar=False,cmap='Pastel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar Graph-\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['label'] = df['label'].astype('category')\n",
    "plt.title('Labels')\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter and density plots-\n",
    "\n",
    "def plotScatterMatrix(df, plotSize, textSize):\n",
    "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
    "    # Remove rows and columns that would lead to df being singular\n",
    "    df = df.dropna('columns')\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    columnNames = list(df)\n",
    "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
    "        columnNames = columnNames[:10]\n",
    "    df = df[columnNames]\n",
    "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
    "    corrs = df.corr().values\n",
    "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
    "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', \n",
    "                          ha='center', va='center', size=textSize)\n",
    "    plt.suptitle('Scatter and Density Plot')\n",
    "    plt.show()\n",
    "    \n",
    "plotScatterMatrix(df, 20, 10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec284d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation-\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "f, ax = plt.subplots(figsize = (12, 9))\n",
    "sns.heatmap(corrmat, vmax = 1, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954def21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Detection-\n",
    "\n",
    "correlation_mat = df.corr().abs()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_mat, dtype = np.bool_))\n",
    "f, ax = plt.subplots(figsize = (40, 40))\n",
    "cmap = sns.diverging_palette(255, 0, as_cmap = True)\n",
    "sns.heatmap(correlation_mat, mask = mask, cmap = cmap,\\\n",
    "vmax = None,center = 0, square = True, annot = True, \\\n",
    "linewidths = .5, cbar_kws = {\"shrink\": 0.9})\n",
    "\n",
    "#Print out almost perfect correlated features-\n",
    "\n",
    "upper_triangle = correlation_mat.where(np.triu(np.ones\\\n",
    "(correlation_mat.shape),k = 1).astype(np.bool_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633f499",
   "metadata": {},
   "source": [
    "## Audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06819f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading a sample audio from the dataset-\n",
    "\n",
    "audio = \"C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\rock\\\\rock.00091.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df ,sr = librosa.load(audio)\n",
    "print(type(df),type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing sample rate to 45600 we obtain the signal value array-\n",
    "\n",
    "librosa.load(audio,sr=45600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking Short-time Fourier transform of the signal-\n",
    "\n",
    "y = librosa.stft(df)  \n",
    "S_db = librosa.amplitude_to_db(np.abs(y), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519038ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio file-\n",
    "\n",
    "import IPython\n",
    "IPython.display.Audio(df,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wave form of the audio-\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.waveshow(df, color=\"#2B4F72\", alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d328c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectrogram of the audio-\n",
    "\n",
    "stft=librosa.stft(df)\n",
    "stft_db=librosa.amplitude_to_db(abs(stft))\n",
    "plt.figure(figsize=(7,6))\n",
    "librosa.display.specshow(stft_db,sr=sr,x_axis='time',y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa91bdf",
   "metadata": {},
   "source": [
    "#### A spectrogram is a visual representation of the signal loudness of a signal over time at different frequencies included in a certain waveform. We can examine increase or decrease of energy over period of time. Spectrograms are also known as sonographs, voiceprints, and voicegrams. We can also know how energy levels change over time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2aa9e1",
   "metadata": {},
   "source": [
    "### 2.1 Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086629a6",
   "metadata": {},
   "source": [
    "#### Extracting Audio features-\n",
    "The process of extraction of features from the data to utilize them for analysis is known as feature extraction. Each audio signal consists of various audio features however we must extract features that are relevant to the problem that we are solving. Here are some features listed which are used in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852eb6f",
   "metadata": {},
   "source": [
    "#### Spectral roll off-\n",
    "It computes the rolloff frequency for each frame in a given signal. The frequency under which some percentage (cutoff) of the total energy of a spectrum is obtained. It can be used to differentiate between the harmonic and noisy sounds. Spectral Roll off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_rolloff=librosa.feature.spectral_rolloff(y=df,sr=sr)[0]\n",
    "plt.figure(figsize=(7,6))\n",
    "librosa.display.waveshow(df,sr=sr,alpha=0.4,color=\"#FF5858\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96604e4f",
   "metadata": {},
   "source": [
    "#### Chroma feature-\n",
    "It closely relates with the twelve different pitch classes. Chroma based features are also called as pitch class profiles. It is the powerful tool for analyzing and categorizing them. Harmonic and melodic characteristics of music are captured by them. Chroma featue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2546ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display as lplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2209188",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y=df,sr=sr)\n",
    "plt.figure(figsize=(7,4))\n",
    "lplt.specshow(chroma,sr=sr,x_axis=\"time\",y_axis=\"chroma\",cmap=\"BuPu\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Chroma Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85c918",
   "metadata": {},
   "source": [
    "#### Zero Crossing Rate-\n",
    "It is the rate at which a signal transitions from positive to zero to negative or from negative to zero or simply said the number of times the signal crosses x-axis is as the zero-crossing rate (ZCR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=1000\n",
    "end=1200\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df[start:end],color=\"#2B4F72\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the number of times signal crosses the x-axis-\n",
    "\n",
    "zero_cross_rate=librosa.zero_crossings(df[start:end],pad=False)\n",
    "print(\"The number of zero_crossings are :\", sum(zero_cross_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c4a5b",
   "metadata": {},
   "source": [
    "### 2.2 EDA OF Audio-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fbd8a",
   "metadata": {},
   "source": [
    "Vizualizing the audio files, wave plots and spectrograms for all the 10 genre classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d5ddd",
   "metadata": {},
   "source": [
    "#### 1. BLUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\blues\\\\blues.00001.wav'\n",
    "df, sr = librosa.load(audio1)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(df, sr=sr,alpha=0.4,)\n",
    "plt.title('Waveplot - BLUES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cab005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - BLUES')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing audio-\n",
    "\n",
    "ipd.Audio(audio1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b72f35",
   "metadata": {},
   "source": [
    "#### 2. CLASSICAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\classical\\\\classical.00001.wav'\n",
    "data, sr = librosa.load(audio2)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(df, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - CLASSICAL') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - CLASSICAL')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc447ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f5792",
   "metadata": {},
   "source": [
    "#### 3. COUNTRY-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2544442",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio3 = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\country\\\\country.00001.wav'\n",
    "data, sr = librosa.load(audio3)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(df, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - COUNTRY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f921c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - COUNTRY')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03346da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47027a",
   "metadata": {},
   "source": [
    "#### 4. DISCO-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe64c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio4= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\disco\\\\disco.00036.wav'\n",
    "data, sr = librosa.load(audio4)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(df, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - DISCO') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c074bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - DISCO')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad713536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec774b",
   "metadata": {},
   "source": [
    "#### 5. HIPHOP-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e44204",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio5 = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\hiphop\\\\hiphop.00001.wav'\n",
    "data, sr = librosa.load(audio5)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(df, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - DISCO') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75888d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - HIPHOP')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2d59d",
   "metadata": {},
   "source": [
    "#### 6. JAZZ-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f78a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio6= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\jazz\\\\jazz.00001.wav'\n",
    "data, sr = librosa.load(audio6)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(data, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - JAZZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - JAZZ')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca12f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03799089",
   "metadata": {},
   "source": [
    "#### 7. METAL-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio7= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\metal\\\\metal.00024.wav'\n",
    "data, sr = librosa.load(audio7)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(data, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - METAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f80b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - METAL')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio7) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbceb61",
   "metadata": {},
   "source": [
    "#### 8. POP-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio8= 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\pop\\\\pop.00028.wav'\n",
    "data, sr = librosa.load(audio8)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(data, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - METAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2978ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - POP')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079d8e4",
   "metadata": {},
   "source": [
    "#### 9. REGGAE-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e186d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio9 = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\reggae\\\\reggae.00030.wav'\n",
    "data, sr = librosa.load(audio9)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(data, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - REGGAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - REGGAE')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d859a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2042be",
   "metadata": {},
   "source": [
    "#### 10. ROCK-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b46dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio10 = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\archive\\\\Data\\\\genres_original\\\\rock\\\\rock.00032.wav'\n",
    "data, sr = librosa.load(audio10)\n",
    "plt.figure(figsize=(7, 3))\n",
    "librosa.display.waveshow(data, sr=sr,alpha=0.4)\n",
    "plt.title('Waveplot - ROCK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating log mel spectrogram-\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "spectrogram = librosa.feature.melspectrogram(y=df, sr=sr, n_mels=128,fmax=8000) \n",
    "spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\n",
    "plt.title('Mel Spectrogram - ROCK')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing audio-\n",
    "\n",
    "ipd.Audio(audio10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66e75a",
   "metadata": {},
   "source": [
    "## Label Encoding and Scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fa705",
   "metadata": {},
   "source": [
    "#### It encodes the categorical classes with numerical integer values for training.\n",
    "\n",
    "Blues - 0<br>\n",
    "Classical - 1<br>\n",
    "Country - 2<br>\n",
    "Disco - 3<br>\n",
    "Hip-hop - 4<br> \n",
    "Jazz - 5 <br> \n",
    "Metal - 6<br> \n",
    "Pop - 7<br>\n",
    "Reggae - 8<br>\n",
    "Rock - 9<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f27578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encod = df.iloc[:,-1]\n",
    "converter = LabelEncoder()\n",
    "y = converter.fit_transform(class_encod)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the column filename as it is no longer required for training- \n",
    "\n",
    "df=df.drop(labels=\"filename\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling-\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "fit=StandardScaler()\n",
    "X=fit.fit_transform(np.array(df.iloc[:,:-1],dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248f7ba",
   "metadata": {},
   "source": [
    "## Building the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86767d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting 70% data into training set and the remaining 30% to test set-\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data size-\n",
    "\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of training data-\n",
    "\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d998f",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965e77c",
   "metadata": {},
   "source": [
    "KNN is a fundamental Machine learning algorithm that is most commonly used among all kinds of problems. It classifies the data points based on the point that is near them by finding the euclidians distance given by d = ((x2-x1)^2 - (y2-y1)^2)^1/2 as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(X_train,y_train)\n",
    "y_pred=clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.3f}\".format(clf1.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97010186",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.set(rc = {'figure.figsize':(8,3)})\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9f8a2",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c1c66",
   "metadata": {},
   "source": [
    "SVM is one of the best machine learning models. Since the data is not linearly separable, we have used the SVM kernel function as sigmoid. The sigmoid function is given by K(yn,yi) = tanh(-gamma*(yn,yi)+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82292253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf', degree=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c08671",
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(svclassifier.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(svclassifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n",
    "cf_matrix3 = confusion_matrix(y_test, y_pred)\n",
    "sns.set(rc = {'figure.figsize':(9,4)})\n",
    "sns.heatmap(cf_matrix3, annot=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb18c8",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3822b",
   "metadata": {},
   "source": [
    "Using neural networks is the best way to classify huge data to draw predictions. Convolutions can solve the given problem very precisely and the algorithm has already been used most widely in classifying the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs,optimizer):\n",
    "    batch_size=256\n",
    "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
    "    return model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validation_plot(history):\n",
    "    print(\"Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
    "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd123f0",
   "metadata": {},
   "source": [
    "Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interface for solving machine learning problems, with a focus on modern deep learning. It provides essential abstractions and building blocks for developing and shipping machine learning solutions with high iteration velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a04b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(64,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(32,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(10,activation='softmax'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.000146)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "model_history=train_model(model=model,epochs=500,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The plot dipicts how training and testing data performed-\n",
    "\n",
    "Validation_plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07addca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample testing-\n",
    "\n",
    "sample = X_test\n",
    "sample = sample[np.newaxis, ...]\n",
    "prediction = model.predict(X_test)\n",
    "predicted_index = np.argmax(prediction, axis = 1)\n",
    "print(\"Expected Index: {}, Predicted Index: {}\".format(y_test, predicted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix for analizing the true positives and negatives-\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "pred_x = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,predicted_index )\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f51df",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "As expected CNN outperformed KNN and SVM. It produced best results in both testing and taring data. As we increased the number of epochs the loss percentage decreased with a gradual increase in accuracy scores. It can be clearly seen in the above validation plot in which the curves almost coincided with each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
